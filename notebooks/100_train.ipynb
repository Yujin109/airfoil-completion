{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yujin109/airfoil-completion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yujin109/airfoil-completion/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">252415-001</strong> at: <a href='https://wandb.ai/yujin109/airfoil_diffusion/runs/kesoqbw3' target=\"_blank\">https://wandb.ai/yujin109/airfoil_diffusion/runs/kesoqbw3</a><br> View project at: <a href='https://wandb.ai/yujin109/airfoil_diffusion' target=\"_blank\">https://wandb.ai/yujin109/airfoil_diffusion</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250415_230726-kesoqbw3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/yujin109/airfoil-completion/wandb/run-20250415_231050-6w4tk4x0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yujin109/airfoil_diffusion/runs/6w4tk4x0' target=\"_blank\">252415-001</a></strong> to <a href='https://wandb.ai/yujin109/airfoil_diffusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yujin109/airfoil_diffusion' target=\"_blank\">https://wandb.ai/yujin109/airfoil_diffusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yujin109/airfoil_diffusion/runs/6w4tk4x0' target=\"_blank\">https://wandb.ai/yujin109/airfoil_diffusion/runs/6w4tk4x0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Weight & Biases のインポートと初期化\n",
    "# ------------------------------------------\n",
    "import wandb\n",
    "wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "\n",
    "# ハイパーパラメータなどの設定\n",
    "execution_name = \"252415-001\"\n",
    "num_epochs = 2000\n",
    "initial_lr = 2e-4\n",
    "b1 = 0.0\n",
    "b2 = 0.0001\n",
    "batch_size = 32\n",
    "diffusion_params = {\"num_timesteps\": 500, \"beta_start\": 1e-4, \"beta_end\": 2e-2}\n",
    "output_mode = \"conv3x3\"\n",
    "\n",
    "wandb.init(\n",
    "    project=\"airfoil_diffusion\",\n",
    "    name=execution_name,\n",
    "    config={\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"initial_lr\": initial_lr,\n",
    "        \"b1\": b1,\n",
    "        \"b2\": b2,\n",
    "        \"diffusion\": diffusion_params,\n",
    "        \"output_mode\": output_mode,\n",
    "        \"dataset_prefix\": \"NACA&Joukowski\",\n",
    "        \"memo\": \"optimizerをAdamに変更\",\n",
    "    },\n",
    ")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. モデルアーキテクチャの定義 (UNet) と LabelEmbedder, UNetConvBlock\n",
    "# ============================================================\n",
    "class LabelEmbedder(nn.Module):\n",
    "    def __init__(self, in_features: int = 2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(512, 1)),  # (B, 512) → (B, 512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, labels: torch.Tensor) -> torch.Tensor:\n",
    "        return self.embed(labels)\n",
    "\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1, padding_mode=\"circular\"),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1, padding_mode=\"circular\"),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1, padding_mode=\"circular\"),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ConditionalUNet(nn.Module):\n",
    "    def __init__(self, in_channels: int = 2, label_dim: int = 2, output_mode: str = \"conv3x3\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): 入力データのチャネル数（例: 座標 x, y）\n",
    "            label_dim (int): 条件情報（例: Cl と t）の次元数\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.output_mode = output_mode\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # Embed label information (e.g. Cl, t)\n",
    "        self.label_embedder = LabelEmbedder(in_features=label_dim)\n",
    "\n",
    "        # Downsampling blocks\n",
    "        self.down1 = UNetConvBlock(in_channels, 64)\n",
    "        self.down2 = UNetConvBlock(64, 128)\n",
    "        self.down3 = UNetConvBlock(128, 256)\n",
    "        self.down4 = UNetConvBlock(256, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = UNetConvBlock(512, 1024)\n",
    "\n",
    "        # Upsampling blocks\n",
    "        self.upconv4 = nn.ConvTranspose1d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.upblock4 = UNetConvBlock(1024, 512)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose1d(512, 256, kernel_size=2, stride=2)\n",
    "        self.upblock3 = UNetConvBlock(512, 256)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose1d(256, 128, kernel_size=2, stride=2)\n",
    "        self.upblock2 = UNetConvBlock(256, 128)\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose1d(128, 64, kernel_size=2, stride=2)\n",
    "        self.upblock1 = UNetConvBlock(128, 64)\n",
    "\n",
    "        # Output Layer\n",
    "        if output_mode == \"conv1x1\":\n",
    "            self.output_layer = nn.Conv1d(64, in_channels, kernel_size=1)\n",
    "        elif output_mode == \"conv3x3\":\n",
    "            self.output_layer = nn.Conv1d(64, in_channels, kernel_size=3, padding=1, padding_mode=\"circular\")\n",
    "        elif output_mode == \"fc\":\n",
    "            self.output_layer = nn.Linear(64 * 248, in_channels * 248)\n",
    "        elif output_mode == \"fc_nn\":\n",
    "            self.output_layer = nn.Sequential(\n",
    "                nn.Linear(64 * 248, 2048),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(2048, 2048),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(2048, 2048),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(2048, 1024),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(1024, in_channels * 248),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid output_mode: {output_mode}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor, c: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): 入力エアフォイルデータ (B, in_channels, 248)\n",
    "            c (Tensor): 条件情報（例: Cl） (B, 1)\n",
    "            t (Tensor): 時間ステップ (B, 1) または (B,) のテンソル\n",
    "        Returns:\n",
    "            Tensor: 生成出力 (B, 2, 248)\n",
    "        \"\"\"\n",
    "        if t.dim() == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "        labels = torch.cat([c, t], dim=1)  # (B, 2)\n",
    "        label_embed = self.label_embedder(labels)  # (B, 512, 1)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = self.down1(x)  # (B, 64, 248)\n",
    "        d2 = self.down2(self.pool(d1))  # (B, 128, 124)\n",
    "        d3 = self.down3(self.pool(d2))  # (B, 256, 62)\n",
    "        d4 = self.down4(self.pool(d3))  # (B, 512, 31)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool(d4))  # (B, 1024, 15)\n",
    "\n",
    "        # Upsampling with skip connections and label conditioning\n",
    "        u4 = self.upconv4(bottleneck)  # (B, 512, 30)\n",
    "        u4 = torch.cat([u4, label_embed], dim=2)  # (B, 512, 31)\n",
    "        u4 = torch.cat([u4, d4], dim=1)  # (B, 1024, 31)\n",
    "        u4 = self.upblock4(u4)  # (B, 512, 31)\n",
    "\n",
    "        u3 = self.upconv3(u4)  # (B, 256, 62)\n",
    "        u3 = torch.cat([u3, d3], dim=1)  # (B, 512, 62)\n",
    "        u3 = self.upblock3(u3)  # (B, 256, 62)\n",
    "\n",
    "        u2 = self.upconv2(u3)  # (B, 128, 124)\n",
    "        u2 = torch.cat([u2, d2], dim=1)  # (B, 256, 124)\n",
    "        u2 = self.upblock2(u2)  # (B, 128, 124)\n",
    "\n",
    "        u1 = self.upconv1(u2)  # (B, 64, 248)\n",
    "        u1 = torch.cat([u1, d1], dim=1)  # (B, 128, 248)\n",
    "        u1 = self.upblock1(u1)  # (B, 64, 248)\n",
    "\n",
    "        if self.output_mode in [\"conv1x1\", \"conv3x3\"]:\n",
    "            return self.output_layer(u1)  # (B, 2, 248)\n",
    "        else:\n",
    "            B = x.size(0)\n",
    "            output = u1.view(B, -1)\n",
    "            output = self.output_layer(output)\n",
    "            return output.view(B, self.in_channels, -1)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Diffuserクラスの定義 (Diffusion Process, 逆拡散)\n",
    "# ============================================================\n",
    "class Diffuser:\n",
    "    def __init__(self, num_timesteps=500, beta_start=1e-4, beta_end=2e-2, device=\"cpu\"):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.device = device\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps, device=device)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "    def add_noise(self, x_0, t):\n",
    "        T = self.num_timesteps\n",
    "        assert (t >= 1).all() and (t <= T).all()\n",
    "        t_idx = t - 1\n",
    "        alpha_bar = self.alpha_bars[t_idx].view(-1, 1, 1)\n",
    "        noise = torch.randn_like(x_0, device=self.device)\n",
    "        x_t = torch.sqrt(alpha_bar) * x_0 + torch.sqrt(1 - alpha_bar) * noise\n",
    "        return x_t, noise\n",
    "\n",
    "    def denoise(self, model, x, t, c):\n",
    "        T = self.num_timesteps\n",
    "        assert (t >= 1).all() and (t <= T).all()\n",
    "\n",
    "        t_idx = t - 1\n",
    "        alpha = self.alphas[t_idx].view(-1, 1, 1)\n",
    "        alpha_bar = self.alpha_bars[t_idx].view(-1, 1, 1)\n",
    "        # alpha_bar_prev = torch.empty_like(alpha_bar)\n",
    "        # alpha_bar_prev[t > 1] = self.alpha_bars[t[t > 1] - 2].view(-1)[t > 1].unsqueeze(1).unsqueeze(1)\n",
    "        # alpha_bar_prev[t == 1] = torch.tensor(1.0, device=self.device)\n",
    "        # 修正ここから\n",
    "        alpha_bar_prev = torch.ones_like(alpha_bar)\n",
    "        mask = (t > 1)\n",
    "        t_minus_2 = t[mask] - 2\n",
    "        alpha_bar_prev[mask] = self.alpha_bars[t_minus_2].view(-1, 1, 1)\n",
    "        # 修正ここまで\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            eps = model(x, c, t)\n",
    "        model.train()\n",
    "        noise = torch.randn_like(x, device=self.device)\n",
    "        noise[t == 1] = 0\n",
    "        mu = (x - ((1 - alpha) / torch.sqrt(1 - alpha_bar)) * eps) / torch.sqrt(alpha)\n",
    "        std = torch.sqrt((1 - alpha) * (1 - alpha_bar_prev) / (1 - alpha_bar))\n",
    "        return mu + noise * std\n",
    "\n",
    "    def generate_from_labels(self, model, labels, coord_shape=(2, 248)):\n",
    "        batch_size = labels.size(0)\n",
    "        x = torch.randn((batch_size, coord_shape[0], coord_shape[1]), device=self.device)\n",
    "        for i in range(self.num_timesteps, 0, -1):\n",
    "            t = torch.full((batch_size,), i, dtype=torch.long, device=self.device)\n",
    "            x = self.denoise(model, x, t, labels[:, 0:1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. データローダー (AirfoilDataset) の読み込み\n",
    "# ============================================================\n",
    "class AirfoilDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        coord_path=\"./dataset/NACA&Joukowski_coords_array.npy\",\n",
    "        cl_path=\"./dataset/NACA&Joukowski_cl_array.npy\",\n",
    "        norm_path=\"./dataset/NACA&Joukowski_normalization_stats.npz\",\n",
    "        normalize=True,\n",
    "    ):\n",
    "        coords_array = np.load(coord_path).astype(np.float32)  # shape: (N, 2, 248)\n",
    "        cls_array = np.load(cl_path).astype(np.float32)[:, np.newaxis]  # shape: (N, 1)\n",
    "\n",
    "        norm = np.load(norm_path)\n",
    "        self.coord_mean = norm[\"coord_mean\"]\n",
    "        self.coord_std = norm[\"coord_std\"]\n",
    "        self.cl_mean = norm[\"cl_mean\"][0]\n",
    "        self.cl_std = norm[\"cl_std\"][0]\n",
    "\n",
    "        if normalize:\n",
    "            coords_array = (coords_array - self.coord_mean) / self.coord_std\n",
    "            cls_array = (cls_array - self.cl_mean) / self.cl_std\n",
    "\n",
    "        self.coords_tensor = torch.tensor(coords_array, dtype=torch.float32)\n",
    "        self.cls_tensor = torch.tensor(cls_array, dtype=torch.float32)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.coords_tensor.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.coords_tensor[idx], self.cls_tensor[idx]\n",
    "\n",
    "    def denormalize_coord(self, coord_tensor):\n",
    "        std = torch.tensor(self.coord_std, dtype=torch.float32, device=coord_tensor.device)\n",
    "        mean = torch.tensor(self.coord_mean, dtype=torch.float32, device=coord_tensor.device)\n",
    "        return coord_tensor * std + mean\n",
    "\n",
    "    def normalize_cl(self, cl_tensor):\n",
    "        std = torch.tensor(self.cl_std, dtype=torch.float32, device=cl_tensor.device)\n",
    "        mean = torch.tensor(self.cl_mean, dtype=torch.float32, device=cl_tensor.device)\n",
    "        return (cl_tensor - mean) / std\n",
    "\n",
    "    def denormalize_cl(self, cl_tensor):\n",
    "        std = torch.tensor(self.cl_std, dtype=torch.float32, device=cl_tensor.device)\n",
    "        mean = torch.tensor(self.cl_mean, dtype=torch.float32, device=cl_tensor.device)\n",
    "        return cl_tensor * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. XFoilを用いたCL評価用関数 (get_cl)\n",
    "# ============================================================\n",
    "\n",
    "from xfoil import XFoil\n",
    "from xfoil.model import Airfoil\n",
    "\n",
    "\n",
    "def get_cl(coord, xf=None, angle=5):\n",
    "    if xf is None:\n",
    "        xf = XFoil()\n",
    "        xf.print = False\n",
    "    xf.Re = 3e6\n",
    "    xf.max_iter = 100\n",
    "    datax, datay = coord.reshape(2, -1)\n",
    "    xf.airfoil = Airfoil(x=datax, y=datay)\n",
    "    c = xf.a(angle)\n",
    "    cl = c[0]\n",
    "    cl = np.round(cl, 10)\n",
    "    return cl\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. 補助関数: running average filter, Convexity Loss, Smoothness Loss, CL Loss\n",
    "# ============================================================\n",
    "def running_average_filter(coord, kernel_size=9):\n",
    "    x, y = coord\n",
    "    x_filtered = np.convolve(x, np.ones(kernel_size) / kernel_size, mode=\"same\")\n",
    "    y_filtered = np.convolve(y, np.ones(kernel_size) / kernel_size, mode=\"same\")\n",
    "    return np.array([x_filtered, y_filtered])\n",
    "\n",
    "\n",
    "def convexity_loss(coord):\n",
    "    x, y = coord\n",
    "    dx = np.diff(x)\n",
    "    dy = np.diff(y)\n",
    "    vectors = np.stack([dx, dy], axis=1)\n",
    "    angles = []\n",
    "    for k in range(len(vectors) - 1):\n",
    "        v1 = vectors[k]\n",
    "        v2 = vectors[k + 1]\n",
    "        norm1 = np.linalg.norm(v1)\n",
    "        norm2 = np.linalg.norm(v2)\n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            angle = 0\n",
    "        else:\n",
    "            dot = np.dot(v1, v2)\n",
    "            cos_angle = np.clip(dot / (norm1 * norm2), -1.0, 1.0)\n",
    "            angle = np.arccos(cos_angle)\n",
    "        angles.append(angle)\n",
    "    return np.sum(angles) / len(angles) if len(angles) > 0 else 0\n",
    "\n",
    "\n",
    "def smoothness_loss(coord):\n",
    "    filtered = running_average_filter(coord, kernel_size=9)\n",
    "    return np.mean((coord - filtered) ** 2)\n",
    "\n",
    "\n",
    "def cl_loss_function(cl_conditioned, cl_evaluated):\n",
    "    return np.mean((cl_conditioned - cl_evaluated) ** 2)\n",
    "\n",
    "\n",
    "def evaluate_generated_samples(samples, conditioned_cls, dataset):\n",
    "    convexity_losses = []\n",
    "    smoothness_losses = []\n",
    "    cl_losses = []\n",
    "    convergence_count_raw = 0\n",
    "    convergence_count_strict = 0\n",
    "\n",
    "    total_count = 0\n",
    "    for i in range(samples.shape[0]):\n",
    "        sample = samples[i].detach().cpu()\n",
    "        sample_denorm = dataset.denormalize_coord(sample).cpu().numpy()\n",
    "        try:\n",
    "            cl_eval = get_cl(sample_denorm, angle=5)\n",
    "        except Exception as _:\n",
    "            cl_eval = None\n",
    "        convexity_l = convexity_loss(sample_denorm)\n",
    "        smoothness_l = smoothness_loss(sample_denorm)\n",
    "        if cl_eval is not None and not np.isnan(cl_eval):\n",
    "            cl_loss_val = cl_loss_function(conditioned_cls[i], cl_eval)\n",
    "            converged = True\n",
    "            convergence_count_raw += 1\n",
    "        else:\n",
    "            cl_loss_val = np.nan\n",
    "            converged = False\n",
    "        convexity_losses.append(convexity_l)\n",
    "        smoothness_losses.append(smoothness_l)\n",
    "        cl_losses.append(cl_loss_val)\n",
    "        if (convexity_l < 0.1 and smoothness_l < 0.1 and cl_loss_val < 0.1) and converged:\n",
    "            convergence_count_strict += 1\n",
    "        total_count += 1\n",
    "    avg_convexity_loss = np.mean(convexity_losses)\n",
    "    avg_smoothness_loss = np.mean(smoothness_losses)\n",
    "    if np.isnan(cl_losses).all() or len(cl_losses) == 0:\n",
    "        avg_cl_loss = 0\n",
    "    else:\n",
    "        avg_cl_loss = np.nanmean(cl_losses)\n",
    "    cl_convergence_ratio_raw = convergence_count_raw / total_count if total_count > 0 else np.nan\n",
    "    cl_convergence_ratio_strict = convergence_count_strict / total_count if total_count > 0 else np.nan\n",
    "    return avg_convexity_loss, avg_smoothness_loss, avg_cl_loss, cl_convergence_ratio_raw, cl_convergence_ratio_strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. 結果保存用のディレクトリ作成\n",
    "# ============================================================\n",
    "output_dirs = {\n",
    "    \"model_info\": f\"./results/{execution_name}/model_info\",\n",
    "    \"training_metrics\": f\"./results/{execution_name}/training_metrics\",\n",
    "    \"evaluation_metrics\": f\"./results/{execution_name}/evaluation_metrics\",\n",
    "    \"samples\": f\"./results/{execution_name}/samples\",\n",
    "    \"weights\": f\"./results/{execution_name}/weights\",\n",
    "}\n",
    "for folder in output_dirs.values():\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "初回保存: モデルパラメータ数: 16314690, モデルサイズ: 65.26 MB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7. 学習ループ・初期設定\n",
    "# ============================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "wandb.config.update({\"device\": str(device)})\n",
    "dataset = AirfoilDataset(normalize=True)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = ConditionalUNet(in_channels=2, label_dim=2, output_mode=output_mode).to(device)\n",
    "diffuser = Diffuser(\n",
    "    num_timesteps=diffusion_params[\"num_timesteps\"],\n",
    "    beta_start=diffusion_params[\"beta_start\"],\n",
    "    beta_end=diffusion_params[\"beta_end\"],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=initial_lr)\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr, betas=(b1, b2))\n",
    "\n",
    "# 最初に1回だけモデルパラメータ数とモデルサイズ(MB)を保存\n",
    "model_param_count = sum(p.numel() for p in model.parameters())\n",
    "model_param_count_path = os.path.join(output_dirs[\"model_info\"], \"model_parameter_count.txt\")\n",
    "with open(model_param_count_path, \"w\") as f:\n",
    "    f.write(f\"Model Parameter Count: {model_param_count}\\n\")\n",
    "model_size_MB = sum(p.nelement() * p.element_size() for p in model.parameters()) / 1e6\n",
    "with open(os.path.join(output_dirs[\"model_info\"], \"model_size_MB.txt\"), \"w\") as f:\n",
    "    f.write(str(model_size_MB))\n",
    "print(f\"初回保存: モデルパラメータ数: {model_param_count}, モデルサイズ: {model_size_MB:.2f} MB\")\n",
    "\n",
    "# モデルサイズなどの静的情報も wandb に記録\n",
    "wandb.config.update({\"model_param_count\": model_param_count})\n",
    "wandb.config.update({\"model_size_MB\": model_size_MB})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習開始...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000 Loss: 0.638536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2000 Loss: 0.252703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/2000 Loss: 0.223204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/2000 Loss: 0.204950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/2000 Loss: 0.181647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/2000 Loss: 0.163695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/2000 Loss: 0.146862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/2000 Loss: 0.134673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/2000 Loss: 0.133606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/2000 Loss: 0.128927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/2000 Loss: 0.123112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/2000 Loss: 0.118273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/2000:  85%|████████▍ | 100/118 [00:02<00:00, 44.26it/s]"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 8. 学習ループ\n",
    "# ============================================================\n",
    "evaluation_interval = 200 # default:200 \n",
    "\n",
    "train_loss_history = []\n",
    "\n",
    "# 各評価指標ごとの時系列履歴 (今後の評価ブロックで利用)\n",
    "eval_history = {\n",
    "    \"convexity_loss_mean\": [],\n",
    "    \"smoothness_loss_mean\": [],\n",
    "    \"cl_loss_mean\": [],\n",
    "    \"cl_convergence_ratio_raw\": [],\n",
    "    \"cl_convergence_ratio_strict\": [],\n",
    "    \"MWT_sampling_sec\": [],\n",
    "    f\"EP_time_sec_for_last_{evaluation_interval}epochs\": [],\n",
    "}\n",
    "\n",
    "prev_eval_time = time.time()\n",
    "\n",
    "print(\"学習開始...\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for x, cl in tqdm(loader, desc=f\"Epoch {epoch}/{num_epochs}\", leave=False):\n",
    "        x = x.to(device)\n",
    "        cl = cl.to(device)\n",
    "        t = torch.randint(low=1, high=diffuser.num_timesteps + 1, size=(x.size(0),), device=device)\n",
    "        x_t, noise = diffuser.add_noise(x, t)\n",
    "        noise_pred = model(x_t, cl, t)\n",
    "        loss = nn.MSELoss()(noise_pred, noise)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    avg_epoch_loss = np.mean(epoch_losses)\n",
    "    train_loss_history.append(avg_epoch_loss)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} Loss: {avg_epoch_loss:.6f}\")\n",
    "\n",
    "    # 学習損失などを wandb に記録\n",
    "    wandb.log({\"train_loss\": avg_epoch_loss, \"epoch\": epoch})\n",
    "\n",
    "    lr_new = initial_lr * ((1 - epoch / num_epochs) ** 0.4)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr_new\n",
    "\n",
    "    # ローカルにも学習履歴を保存\n",
    "    with open(os.path.join(output_dirs[\"training_metrics\"], \"training_loss_history.txt\"), \"a\") as f:\n",
    "        f.write(f\"{epoch},{avg_epoch_loss}\\n\")\n",
    "\n",
    "    if epoch % evaluation_interval == 0 or epoch == num_epochs:\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, len(train_loss_history) + 1), train_loss_history, marker=\"o\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Diffusion Loss (log scale)\")\n",
    "        plt.title(\"Training Diffusion Loss\")\n",
    "        plt.tight_layout()\n",
    "        loss_plot_path = os.path.join(output_dirs[\"training_metrics\"], f\"loss_epoch_{epoch}.png\")\n",
    "        plt.savefig(loss_plot_path)\n",
    "        plt.close()\n",
    "        # wandb に画像をアップロード\n",
    "        wandb.log({\"loss_plot\": wandb.Image(loss_plot_path), \"epoch\": epoch})\n",
    "\n",
    "    if epoch % evaluation_interval == 0:\n",
    "        eval_start = time.time()\n",
    "        print(f\"--- Evaluation at epoch {epoch} ---\")\n",
    "\n",
    "        cl_eval_values = np.linspace(0.5, 1.2, 71)\n",
    "        num_samples_for_each_cl = 10  # default:10\n",
    "        convexity_list = []\n",
    "        smoothness_list = []\n",
    "        cl_loss_list = []\n",
    "        convergence_ratios_raw = []\n",
    "        convergence_ratios_strict = []\n",
    "        for cl_val in tqdm(cl_eval_values):\n",
    "            cond = torch.tensor([[cl_val, 0.0]] * num_samples_for_each_cl, dtype=torch.float32, device=device)\n",
    "            cond_norm = dataset.normalize_cl(cond)\n",
    "            generated = diffuser.generate_from_labels(model, cond_norm, coord_shape=(2, 248))\n",
    "            cl_conditioned = np.array([cl_val] * num_samples_for_each_cl)\n",
    "            conv_l, smooth_l, cl_l, conv_ratio_raw, conv_ratio_strict = evaluate_generated_samples(\n",
    "                generated, cl_conditioned, dataset\n",
    "            )\n",
    "            convexity_list.append(conv_l)\n",
    "            smoothness_list.append(smooth_l)\n",
    "            cl_loss_list.append(cl_l)\n",
    "            convergence_ratios_raw.append(conv_ratio_raw)\n",
    "            convergence_ratios_strict.append(conv_ratio_strict)\n",
    "\n",
    "        eval_metrics = {\n",
    "            \"convexity_loss_mean\": np.mean(convexity_list),\n",
    "            \"smoothness_loss_mean\": np.mean(smoothness_list),\n",
    "            \"cl_loss_mean\": np.mean(cl_loss_list),\n",
    "            \"cl_convergence_ratio_raw\": np.mean(convergence_ratios_raw),\n",
    "            \"cl_convergence_ratio_strict\": np.mean(convergence_ratios_strict),\n",
    "        }\n",
    "\n",
    "        # MWT Sampling: 1サンプル生成の平均wall time (例として100サンプル)\n",
    "        sample_times = []\n",
    "        num_sample = 100  # default:100\n",
    "        cond = torch.tensor([[0.8, 0.0]] * 1, dtype=torch.float32, device=device)\n",
    "        cond_norm = dataset.normalize_cl(cond)\n",
    "        for _ in range(num_sample):\n",
    "            start_t = time.time()\n",
    "            _ = diffuser.generate_from_labels(model, cond_norm, coord_shape=(2, 248))\n",
    "            sample_times.append(time.time() - start_t)\n",
    "        eval_metrics[\"MWT_sampling_sec\"] = np.mean(sample_times)\n",
    "\n",
    "        ep_time = time.time() - prev_eval_time\n",
    "        prev_eval_time = time.time()\n",
    "        eval_metrics[f\"EP_time_sec_for_last_{evaluation_interval}epochs\"] = ep_time\n",
    "\n",
    "        # 各指標を wandb に記録\n",
    "        wandb.log({**eval_metrics, \"epoch\": epoch})\n",
    "\n",
    "        # 各指標ごとの履歴保存と画像作成\n",
    "        for key, value in eval_metrics.items():\n",
    "            eval_history[key].append((epoch, value))\n",
    "            epochs_list, values_list = zip(*eval_history[key])\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_list, values_list, marker=\"o\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(key)\n",
    "            plt.title(f\"{key} over Evaluations (up to epoch {epoch})\")\n",
    "            plt.tight_layout()\n",
    "            metric_plot_path = os.path.join(output_dirs[\"evaluation_metrics\"], f\"{key}_epoch_{epoch}.png\")\n",
    "            plt.savefig(metric_plot_path)\n",
    "            plt.close()\n",
    "            print(f\"{key}の評価グラフ保存: {metric_plot_path}\")\n",
    "            # wandb に画像をアップロード\n",
    "            wandb.log({f\"{key}_plot\": wandb.Image(metric_plot_path), \"epoch\": epoch})\n",
    "            data_save_path = os.path.join(output_dirs[\"evaluation_metrics\"], f\"{key}_data_epoch_{epoch}.txt\")\n",
    "            with open(data_save_path, \"w\") as f:\n",
    "                f.write(\"Epoch,Value\\n\")\n",
    "                for e, val in eval_history[key]:\n",
    "                    f.write(f\"{e},{val}\\n\")\n",
    "            print(f\"{key}の生データ保存: {data_save_path}\")\n",
    "\n",
    "        # 8条件 (CL = [0.5,0.6,...,1.2]) でのサンプルプロット (5サンプルずつ, 5行×8列)\n",
    "        cl_plot_values = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "        fig, axs = plt.subplots(5, len(cl_plot_values), figsize=(20, 12))\n",
    "        for col, cl_val in enumerate(cl_plot_values):\n",
    "            cond = torch.tensor([[cl_val, 0.0]] * 5, dtype=torch.float32, device=device)  # default:5\n",
    "            cond_norm = dataset.normalize_cl(cond)\n",
    "            generated = diffuser.generate_from_labels(model, cond_norm, coord_shape=(2, 248))\n",
    "            for row in range(5):  # default:5\n",
    "                sample = generated[row].detach().cpu()\n",
    "                sample_denorm = dataset.denormalize_coord(sample).cpu().numpy()\n",
    "                x_coord = sample_denorm[0, :]\n",
    "                y_coord = sample_denorm[1, :]\n",
    "                try:\n",
    "                    cl_eval = get_cl(sample_denorm, angle=5)\n",
    "                except Exception as e:\n",
    "                    cl_eval = np.nan\n",
    "                conv_loss = convexity_loss(sample_denorm)\n",
    "                axs[row, col].plot(x_coord, y_coord)\n",
    "                axs[row, col].set_title(f\"CL: {cl_eval:.2f}\\nConv: {conv_loss:.3f}\", fontsize=8)\n",
    "                axs[row, col].tick_params(labelsize=6)\n",
    "                axs[row, col].grid(True)\n",
    "        plt.tight_layout()\n",
    "        sample_plot_path = os.path.join(output_dirs[\"samples\"], f\"samples_epoch_{epoch}.png\")\n",
    "        plt.savefig(sample_plot_path)\n",
    "        plt.close()\n",
    "        print(f\"生成サンプルプロット保存: {sample_plot_path}\")\n",
    "        wandb.log({\"generated_samples\": wandb.Image(sample_plot_path), \"epoch\": epoch})\n",
    "\n",
    "        # ★ {evaluation_interval}epoch毎に中間モデルの重みを保存 (拡張子 .pth)\n",
    "        intermediate_model_path = os.path.join(output_dirs[\"weights\"], f\"model_weights_epoch_{epoch}.pth\")\n",
    "        torch.save(model.state_dict(), intermediate_model_path)\n",
    "        print(f\"Epoch {epoch}: 中間モデルの重み保存: {intermediate_model_path}\")\n",
    "        wandb.save(intermediate_model_path)\n",
    "\n",
    "# ============================================================\n",
    "# 9. 学習終了後，最終モデルの重みを保存\n",
    "# ============================================================\n",
    "final_model_path = os.path.join(output_dirs[\"weights\"], \"final_model_weights.pt\")\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"学習終了．最終モデルの重み保存: {final_model_path}\")\n",
    "wandb.save(final_model_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
